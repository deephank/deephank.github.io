<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="/css/materialize.css">
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="/css/prettify.css">

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.10/css/all.css" integrity="sha384-+d0P83n9kaQMCwj8F4RJB66tzIwOKmrdb46+porD/OvrJ+37WqIM7UoBtwHO6Nlg" crossorigin="anonymous">


    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    
    <script>
    function randthumbnail(){
        var randomNum = Math.floor(Math.random()*15);
        return "/images/"+randomNum+".png"
    }
    </script>


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <title>RNN實作PTT文章分類 - luuuy@blog</title>    
    
    
</head>

<body onload="PR.prettyPrint()">
    <a href="#" data-target="slide-out" class="sidenav-trigger">
        <i class="Small material-icons">menu</i>
    </a>

    <div class="container">
    <!-- <nav>
  <a href="/" class="brand-logo center">luuuy@blog</a>
</nav> -->


<ul id="slide-out" class="sidenav">
    <li><div class="user-view">
      <div class="background">
        <img src="/images/side-bg.jpg">
      </div>
      <a href="/"><img class="circle" src="/images/avatar.png"></a>
      <a href=""><span class="white-text name">Hank Lu</span></a>
      <a href=""><span class="white-text email">s210215@shsh.tw</span></a>
    </div></li>
    <li><a href="https://github.com/" target="_blank"><i class="fab fa-github fa-2x"></i>GitHub</a></li>
    <li><a href="https://medium.com/@luuuy" target="_blank"><i class="fab fa-medium fa-2x"></i>Medium</a></li>
    <li><div class="divider"></div></li>
    <li><a class="subheader">@TaiwanTech</a></li>
    <!-- <li><a class="waves-effect" href="#!">Third Link With Waves</a></li> -->
</ul>
  
    <div class="row">
    <div class="blog-post z-depth-1">
        
        <div class="blog-post-thumbnail">
            
            <a href="/RNN實作PTT文章分類/" class="blog-post-title">
                <h1 >RNN實作PTT文章分類</h1>
            </a>
            
        </div>

        <!-- Content -->
        <div class="blog-post-content">
        <p>「自然語言處理導論作業3」使用word2vec + RNN 分類 PTT 文章。<a href="https://www.kaggle.com/c/deeplearningfornaturallanguageprocessinghw3" target="_blank" rel="noopener">Kaggle</a><br>這篇文部分參考了<a href="https://www.kaggle.com/c/deeplearningfornaturallanguageprocessinghw3/kernels" target="_blank" rel="noopener">Kaggle上的佛心學長</a>的文章</p>
<a id="more"></a>
<h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p>訓練資料為 9000 篇來自 10 個版的文章，助教提供的版本有斷詞及未斷詞的版本。預測 1000 篇文章在哪個版。</p>
<pre><code class="python">category2idx = {&#39;Japan_Travel&#39;: 0, &#39;KR_ENTERTAIN&#39;: 1, &#39;Makeup&#39;: 2, &#39;Tech_Job&#39;: 3, &#39;WomenTalk&#39;: 4, &#39;babymother&#39;: 5, &#39;e-shopping&#39;: 6, &#39;graduate&#39;: 7, &#39;joke&#39;: 8, &#39;movie&#39;: 9}
# 某一篇 Training
這兩天 / 看到 / 版友 / 接近 / 寶寶學會 / 走路 / 月齡 / 底線 / 還遲 / 遲不會 / 走 / 緊張 / 苦惱 / 分享 / 一下 / 中榮 / 復 / 健老師 / 邊學 / 回來 / 技巧 / 希望 / 需要 / 馬 / 麻們 / 有所 / 幫助
# 某一篇 Testing
spanclassf2 / 引述 / mvpmanmvp / 之銘言 / spanspanclassf6 / 想 / 請問 / 一下 / 經驗 / 朋友 / spanspanclassf6 / 河南 / 鄭州 / 生活 / 條件 / 狀況 / spanspanclassf6 / 文化 / 飲食 / 交通 / 娛樂 / etcspanspanclassf6 / 台商 / 台灣 / 人
</code></pre>
<h2 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h2><h3 id="使用-jieba-分詞"><a href="#使用-jieba-分詞" class="headerlink" title="使用 jieba 分詞"></a>使用 jieba 分詞</h3><p>因為助教提供的資料沒有分得很好，所以手動加入了一些詞（約 2000 個），讓一些特定的詞能夠被分出來，如：<br><code>鄉民用語：肥宅、女孩、撒花、媽寶、就可、韓綜</code><br><code>特殊名詞：研替、沖繩、台積電、竹科、台大、政大、投履歷、分紅</code><br><code>人名、地名、片名：詹姆士、湯姆、東京、六本木、大阪市、冬季戀歌</code><br>然後再移除一些符號，如圖片超連結、span、class等等，考慮到圖片有可能影響結果所以將所有圖片tag換成同一個字代表。這樣處理的確能讓 w2v 的訓練結果好一點，但事後發現在 RNN 時沒有很顯著的提升（和助教切割版比較）。</p>
<h6 id="cut-word-py"><a href="#cut-word-py" class="headerlink" title="cut_word.py"></a>cut_word.py</h6><pre><code class="python">import os
import pandas as pd
import jieba

TRAINING_PATH = &#39;data/training/&#39;
TESTING_PATH = &#39;data/testing/&#39;
PKL_PATH = &#39;pkl/&#39;

jieba.load_userdict(&quot;w2v_model/userdict.txt&quot;) # 自定義的字典

# ----- CUT sigle post -----
# 移除一些雜詞
def cut_post(post):
    words = jieba.cut(post)
    def determine(x):
        rmv_list = [&#39;gtlt&#39;, &#39;span&#39;, &#39;gtult&#39;, &#39;class&#39;]
        for e in rmv_list:
            if e in x:
                return False
        return True
    new_lst = []
    for w in words:
        if &#39;href&#39; in x:
            new_lst.append(&#39;href&#39;)
        elif determine(w):
            new_lst.append(w)
    return new_lst

# ----- CUT TRAIN -----
# 把已經分詞過的字接起來，重新分詞一次
train_list = []
# 處理 10 個分類裡的 9000 篇訓練資料
for category in category2idx.keys():
    category_path = TRAINING_PATH + category + &#39;_cut/&#39;
    category_idx = category2idx[category]
    print(category_path)
    for filename in os.listdir(category_path):
        print(filename)
        with open(category_path + filename, encoding=&#39;utf-8&#39;) as file:
            post = &#39;&#39;.join(file.read().strip().split(&#39; / &#39;))
            words = cut_post(post)
            train_list.append([words, category_idx])

train_df = pd.DataFrame(train_list, columns=[&quot;text&quot;, &quot;category&quot;])
print(&quot;Shape:&quot;, train_df.shape) # Shape: (9000, 2)

train_df.to_pickle(PKL_PATH + &#39;train_cut.pkl&#39;) # 存成 pkl
</code></pre>
<p><code>print(train_df.sample(5))</code> 把資料分成單詞的 list 及該文章對應的 category</p>
<table>
<thead>
<tr>
<th></th>
<th>text</th>
<th>category</th>
</tr>
</thead>
<tbody>
<tr>
<td>6968</td>
<td>[中興, 材料, 成大, 醫工, 材料, 組對, 生醫, 材料, 有興趣, 聽, 說, 台灣…</td>
<td>7</td>
</tr>
<tr>
<td>258</td>
<td>[href, 無, 音樂, 圖, 網誌, 好, 讀版, 晚安, 今天, 介紹, 深夜, 東京…</td>
<td>0</td>
</tr>
<tr>
<td>6226</td>
<td>[href, 這件, 適合, 大, 胸部, 女生, 34DE, 適合, 推薦, 哪件, 碎花…</td>
<td>6</td>
</tr>
<tr>
<td>7829</td>
<td>[還好, 還來, 今天, 爆笑, 主要, href, 備用, href, ptt, joke…</td>
<td>8</td>
</tr>
<tr>
<td>8698</td>
<td>[電影, 板, 首po, 文筆, 不好, 請見, 諒板, 已經, 有, 幾篇關, 陰緣, 詳…</td>
<td>9</td>
</tr>
</tbody>
</table>
<p>如法炮製 test_data</p>
<pre><code class="python">test_list = []
for idx in range(1000):
    filepath = TESTING_PATH + str(idx) + &#39;.txt&#39;
    with open(filepath, encoding=&#39;utf-8&#39;) as file:
        print(str(idx) + &#39;.txt&#39;)
        post = &#39;&#39;.join(file.read().strip().split(&#39; / &#39;))
        words = cut_words(post)
        words = remove_words(words)
        test_list.append([words,idx])
    test_df = pd.DataFrame(test_list, columns=[&quot;id&quot;, &quot;text&quot;])
print(&quot;Shape:&quot;, test_df.shape)

test_df.to_pickle(PKL_PATH + &#39;test_cut.pkl&#39;)
</code></pre>
<h2 id="W2V-model"><a href="#W2V-model" class="headerlink" title="W2V model"></a>W2V model</h2><p>做完資料的前處理後，可以開始用 word2vec 訓練詞向量模型了，越好的詞向量模型可以做出更好的預測。</p>
<h6 id="w2v-model-py"><a href="#w2v-model-py" class="headerlink" title="w2v_model.py"></a>w2v_model.py</h6><pre><code class="python">import pandas as pd
from datetime import datetime
from gensim.models import word2vec

PKL_PATH = &#39;pkl/&#39;
train_df = pd.read_pickle(PKL_PATH + &quot;train_cut.pkl&quot;)
test_df = pd.read_pickle(PKL_PATH + &quot;test_cut.pkl&quot;)
corpus = pd.concat([train_df.text, test_df.text]).sample(frac=1) # 打亂

# 訓練模型
w2v_model = word2vec.Word2Vec(corpus, size=250, iter=15, sg=1)

# 把訓練好的模型儲存下來
# 因為需要常常調整&amp;重新訓練模型，所以檔名加上時間比較好區別個別的 model
w2v_model.save(&#39;w2v_model/word2vec_&#39; + datetime.now().strftime(&#39;%m%d%H%M&#39;) + &#39;.model&#39;)
</code></pre>
<p>測試一下，使用<a href="https://www.kaggle.com/c/deeplearningfornaturallanguageprocessinghw3/kernels" target="_blank" rel="noopener">Kaggle上的佛心學長</a>的 function</p>
<pre><code>from random import sample
def most_similar(w2v_model, words, topn=10):
    similar_df = pd.DataFrame()
    for word in words:
        try:
            similar_words = pd.DataFrame(w2v_model.wv.most_similar(word, topn=topn), columns=[word, &#39;cos&#39;])
            similar_df = pd.concat([similar_df, similar_words], axis=1)
        except:
            print(word, &quot;not found in Word2Vec model!&quot;)
    return similar_df

# 隨機從 train_df 選字出來比較相似度
sample = sample(list(w2v_model.wv.vocab.keys()),5)
most_similar(w2v_model, sample)
</code></pre><table>
<thead>
<tr>
<th></th>
<th>CP值</th>
<th>cos</th>
<th>鄉民</th>
<th>cos</th>
<th>質感</th>
<th>cos</th>
<th>月薪</th>
<th>cos</th>
<th>吸引</th>
<th>cos</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>物超所值</td>
<td>0.535514</td>
<td>大感謝</td>
<td>0.545827</td>
<td>沉甸甸</td>
<td>0.596332</td>
<td>調薪</td>
<td>0.707780</td>
<td>目光</td>
<td>0.497895</td>
</tr>
<tr>
<td>1</td>
<td>耐操</td>
<td>0.519590</td>
<td>內情</td>
<td>0.536258</td>
<td>這件蕾絲</td>
<td>0.570542</td>
<td>簽約金</td>
<td>0.693079</td>
<td>轉睛</td>
<td>0.385460</td>
</tr>
<tr>
<td>2</td>
<td>比高</td>
<td>0.498523</td>
<td>這先</td>
<td>0.524160</td>
<td>壓紋</td>
<td>0.569111</td>
<td>N14</td>
<td>0.685485</td>
<td>注目</td>
<td>0.384905</td>
</tr>
<tr>
<td>3</td>
<td>打平</td>
<td>0.495074</td>
<td>發在</td>
<td>0.521243</td>
<td>質料</td>
<td>0.567561</td>
<td>底薪</td>
<td>0.674227</td>
<td>每棵</td>
<td>0.381651</td>
</tr>
</tbody>
</table>

        </div>

        <div class="fixed-action-btn">
          <a class="btn-floating btn-large teal">
            <i class="material-icons">add</i>
          </a>
          <ul>
            <li><a class="btn-floating teal lighten-2" href="/"><i class="material-icons">home</i></a></li>
            <li onclick="$('html,body').animate({scrollTop:0},'slow')">
                <a class="btn-floating teal lighten-1"><i class="material-icons">keyboard_arrow_up</i></a>
            </li>
          </ul>
        </div>

    </div>
</div>

    </div>
</body>
<script src="/js/prettify.js"></script>
<script src="/js/materialize.js"></script>
<script>$('pre').addClass('prettyprint linenums')</script>

<script>
    $('.blog-post-thumbnail').css("background-image", "url("+randthumbnail()+")");

    $('.card-image').each(function(){
        $(this).children().attr('src',randthumbnail());
    })
</script>


<script>
  $(document).ready(function(){
    $('.sidenav').sidenav();
  });

   $('.fixed-action-btn').floatingActionButton({
    direction: 'top',
  });
   $('.fixed-action-btn').floatingActionButton('open');
</script>
</html>
